{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"image_classifier.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2haG1-Z8wYHp"},"source":["Image classifier for team ornithomimus.\n","---\n","Here's the basics of this model: \n","\n","The purpose of this classifier is to predict if a user will like or dislike a specific image. To do this, we build up a dataset of images that the user has marked as liked or disliked while swiping on the app. Any image that the user has seen is used in the training dataset, and any image that the user has not seen is used in the \"validation\" dataset.\n","\n","Due to the small size of our training dataset, we want to make the best use of these images as we can. As a result, we should use all images for training and save none for validation; validation does not help us reduce loss, so there is no practical reason for using it, except for checking that the model is making better predictions that random guessing (for testing, we may want to curate a larger dataset of likes and dislikes from one person to see that the model is working). In addition, we will likely want to do some image augmentation to increase the number of images the models sees. The only image transforms that make sense for this dataset are horizontal flips and subtle colour and image manipulation (greyscale, blur, crop). Since we want to consider the entire landscape of what the user saw in an image, it is impractical to use rotation, vertical flips, large crops or significant colour distortion.\n"]},{"cell_type":"code","metadata":{"id":"5NiGP0XnwXnC"},"source":["# Imports\n","import torch, torchvision\n","from torch import nn, optim\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gtAOrbYW4R0z"},"source":["TODO:\n","---\n","1. Recieve ratings from user, parse information\n","2. Based on ratings, move appropriate photos from testing dataset into training dataset, labelled with rating\n","3. Train model using updated dataset\n","4. Test model to get recommended photos, do something with the output\n"]},{"cell_type":"code","metadata":{"id":"QjMbsPEK4RNi"},"source":["# Make a model\n","# TBD: do we want to output a binary like/dislike, or should we send the like probability to recommender model for more detail?\n","\n","model = models.resnet18(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, 2)\n","torch.nn.init.xavier_uniform_(guitar_model.fc.weight)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OqpWTHOVwEo7"},"source":[""],"execution_count":null,"outputs":[]}]}